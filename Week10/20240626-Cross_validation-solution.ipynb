{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eeb1ec4-82f9-40e4-b16d-3468980670f8",
   "metadata": {},
   "source": [
    "# Part 1: Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6c8919-3445-43b8-a26c-f0b16e5eb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold,\n",
    "      ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf2c30f4-852b-4370-beb5-71fe23129186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6658e92-57c5-4a9b-aab5-6cfecab57823",
   "metadata": {},
   "source": [
    "In this part we follow the first part of the lab of Section 4 of our textbook to learn how to implement cross validation in Python (see [here](https://islp.readthedocs.io/en/latest/labs/Ch05-resample-lab.html) for the original version of the Lab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96850968-33fe-4daa-bf81-2f86895c55d3",
   "metadata": {},
   "source": [
    "## 1a) Validation set approach\n",
    "\n",
    "**Objective of part 1a)**: Use the validation set approach to evaluate the performance of a model predicting `mpg` in the `Auto` dataset based on predictor `horsepower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457e761-a423-4dee-8356-d10e3f4542cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load the dataset\n",
    "Auto =  load_data('Auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e9761-f72a-4ce0-9723-080b5a3171f9",
   "metadata": {},
   "source": [
    "### Task 1.1: \n",
    "Split the dataset into a train and a test part. Your test set should have 196 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36d2ee-a8e5-4158-9ee5-733b9a51366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(Auto, test_size=196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cbaa86-66fd-4a23-be60-5443d89c1156",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee215e-c079-458e-87ea-a3c2ec6eefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d2b39b-7599-439b-ac63-c2479a53528f",
   "metadata": {},
   "source": [
    "### Task 1.2:\n",
    "Train a simple linear regression model on the training set which predicts `mpg` based on the unique predictor `horsepower`. Make sure to use the training set to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b44d2-9f57-413f-99f2-6d15d510fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = MS(['horsepower']).fit(train)\n",
    "X_train = design.transform(train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5a6ba3-72ee-4888-a78f-c562ea2a3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa2bdf-bd80-4562-9ffa-2cd30759328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train,X_train)\n",
    "results = model.fit()\n",
    "summarize(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa26e0-358f-45b7-8369-f8bde3e86490",
   "metadata": {},
   "source": [
    "### Task 1.3: \n",
    "Now use the validation set to compute an estimate for the model's MSE (mean squared error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5f8e8-3d24-474a-ad60-2745370bc90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_actual = validation.mpg\n",
    "X_validation = design.transform(validation)\n",
    "y_valid_predicted = results.predict(X_validation)\n",
    "MSE = np.mean((y_valid_actual - y_valid_predicted)**2)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e314e11d-62cb-4628-9732-84bec212d1ef",
   "metadata": {},
   "source": [
    "### Task 1.4:\n",
    "Below you find a preimplemented function `evalMSE()`. Explain what this function does (what are the arguments, what is the output)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a5c7f-e682-4878-a276-9ecd4d89c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(predictors,\n",
    "           train,\n",
    "           validation):\n",
    "    # build design matrix and response vector\n",
    "    design = MS(predictors).fit(train)\n",
    "    X_train = design.transform(train)\n",
    "    y_train = train.mpg \n",
    "\n",
    "    # train model\n",
    "    model = sm.OLS(y_train,X_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    # compute MSE\n",
    "    y_valid_actual = validation.mpg\n",
    "    X_validation = design.transform(validation)\n",
    "    y_valid_predicted = results.predict(X_validation)\n",
    "    MSE = np.mean((y_valid_actual - y_valid_predicted)**2)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e191ba-e982-49d9-8ab6-08049617d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalMSE(['horsepower'], train, validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a5417-6aa1-4e53-8236-6f3e892a5578",
   "metadata": {},
   "source": [
    "*Solution*: The function takes a set of predictors, a dataframe of training data and a dataframe of validation data as inputs. Based on these it trains a linear regression model on the training data using the predictors provided as arguments. It then computes the test MSE on the provided validation set. This test MSE is then returned as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c61267-f21a-4fd4-9a65-5eeb6f23e66c",
   "metadata": {},
   "source": [
    "### Task 1.5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f91f4-2687-4f2f-a70c-fc3ff9244364",
   "metadata": {},
   "source": [
    "Use the function `evalMSE()` to estimate the MSE on the validation set for linear regression models including successively higher polynomial terms of `horsepower` ranging from degree 1 to degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b00966-81a0-42e0-9fb4-fffc45eae41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP.models import poly\n",
    "MSE = []\n",
    "for i in range(1,4):\n",
    "    predictors = [poly('horsepower', i+1)] # choose powers of horsepower as predictors up to degree i+1\n",
    "    err = evalMSE(predictors, train, validation)\n",
    "    MSE.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa354b40-ee8e-4c0b-ae27-7e9002fd3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4fc03-91ec-4082-a410-10be246d127a",
   "metadata": {},
   "source": [
    "## 1b) Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2bc1aa-9654-41b3-a459-69777ab0f732",
   "metadata": {},
   "source": [
    "Cross validation is implemented most comfortably in `scikit-learn`. In order to use the `scikit-learn` implementation of cross validation with our `statsmodels` linear model, we use the wrapper `sklearn_sm` provided by the `ISLP` library. From the lab in Chapter 5:\n",
    "\n",
    "\"The class `sklearn_sm()` has as its first argument a model from `statsmodels`. It can take two additional optional arguments: `model_str` which can be used to specify a formula, and `model_args` which should be a dictionary of additional arguments used when fitting the model. For example, to fit a logistic regression model we have to specify a family argument. This is passed as `model_args={'family':sm.families.Binomial()}`.\"\n",
    "\n",
    "After specifying our design matrix `X` and the vector `y` we call the `scikit-learn` function `cross_validate` (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)).\n",
    "\n",
    "The result is a dictionary which among others contains the `test_score` which we are interested when we use cross validation to estimate the test error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c8355-3688-4337-85c5-fc83214929a7",
   "metadata": {},
   "source": [
    "### Task 1.6:\n",
    "Run the following cell to initialize an `sklearn_sm` object with a `statsmodels.OLS` model and a `ModelSpec` object with specified predictor `horsepower`, with dataset `X` with removed `mpg` column und with response vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5041bb1a-9938-4979-a691-15c445c3e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn_sm(sm.OLS,\n",
    "                  MS(['horsepower']))\n",
    "X = Auto.drop(columns = ['mpg'])\n",
    "y = Auto['mpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda468f9-0b66-4be7-b77f-7df234e958ae",
   "metadata": {},
   "source": [
    "The function `cross_validate` is the original `scikit-learn` function which carries out cross validation. We provide the following arguments:\n",
    "- a model which needs `fit()` and `predict()` methods\n",
    "- a design matrix `X` and a vector of training labels `y`\n",
    "- the parameter `cv` specifying the number of folds for cross validation.\n",
    "\n",
    "See the [official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1422be8-ca48-47e8-907a-3479d8211665",
   "metadata": {},
   "source": [
    "### Task 1.7:\n",
    "Run a Leave-one-out-cross-validation for a simple linear regression model predicting `mpg` based on `horsepower`. To do so, choose as many folds as your dataset has samples using the parameter `cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd5f297-f0d1-464e-8725-06a8f124cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model,\n",
    "                           X,\n",
    "                           y,\n",
    "                           cv = Auto.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca322d25-319b-4fd0-a6a4-334f853d7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf47539-a394-47a2-aac3-aae2a7b5f766",
   "metadata": {},
   "source": [
    "### Task 1.8:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa31f5-b248-486a-a787-4237be3eadbe",
   "metadata": {},
   "source": [
    "We can repeat this procedure to compare different models. In the following we do this with various polynomial fits.\n",
    "\n",
    "Compute the LOOCV error for models to predict `mpg` based on polynomial powers of `mpg` for degrees 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f618abc-ec1d-4ead-907d-1c1bc58326b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_error = np.zeros(5) #initialize empty vector for CV errors of 5 models\n",
    "M = sklearn_sm(sm.OLS)\n",
    "y = Auto['mpg']\n",
    "\n",
    "# loop over 5 different polynomial models\n",
    "for i in range(1,6):\n",
    "    # choose power of horsepowers as predictors up to degree i+1\n",
    "    predictors = [poly('horsepower', i+1)]\n",
    "    X = MS(predictors).fit_transform(Auto)\n",
    "    #perform cross validation for polynomial model of degree i+i\n",
    "    cv_results = cross_validate(M,\n",
    "                               X,\n",
    "                               y,\n",
    "                               cv = Auto.shape[0])\n",
    "    # save cross validation error into result vector\n",
    "    cv_error[i] = np.mean(cv_results['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a05819-9a75-4f48-ac7b-4fc629b2e076",
   "metadata": {},
   "source": [
    "### Task 1.9:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d9e78a-7e5a-438c-a279-8c95266cb9db",
   "metadata": {},
   "source": [
    "Instead of using $K = n$ folds such as above (resulting in Leave-One-Out-Cross-Validation (LOOCV)) we can also specify a smaller integer $K$ of folds. There are two possibilities for this:\n",
    "- set `cv = K`,\n",
    "- specify a cross validation generator such as `KFold` (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html))\n",
    "\n",
    "It is recommended to use the second approach, which is generally preferred as we do better control the kind of split when using `KFold`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b0f54-a969-4661-85cd-fc8092d3bdda",
   "metadata": {},
   "source": [
    "Compute the cross validation error for models to predict `mpg` based on polynomial powers of `mpg` for degrees 1 to 5. Use 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492bb369-e65b-41a5-b3d6-454403f44e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_error = np.zeros(5)\n",
    "\n",
    "cross_val = KFold(n_splits = 10,\n",
    "                 shuffle = True,\n",
    "                 random_state = 42)\n",
    "\n",
    "M = sklearn_sm(sm.OLS)\n",
    "y = Auto['mpg']\n",
    "\n",
    "# loop over 5 different polynomial models\n",
    "for i in range(5):\n",
    "    # choose power of horsepowers as predictors up to degree i+1\n",
    "    predictors = [poly('horsepower', i+1)]\n",
    "    X = MS(predictors).fit_transform(Auto)\n",
    "    #perform cross validation for polynomial model of degree i+i\n",
    "    cv_results = cross_validate(M,\n",
    "                               X,\n",
    "                               y,\n",
    "                               cv = cross_val)\n",
    "    # save cross validation error into result vector\n",
    "    cv_error[i] = np.mean(cv_results['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab36e5-c629-4ae3-8783-89823f392af7",
   "metadata": {},
   "source": [
    "# Part 2: Case study cross validation (no solutions beyond this point as we did not get further in lecture)\n",
    "\n",
    "(see Exercise 5.4.5)\n",
    "\n",
    "In this case study we use the credit card dataset to predict the probability of default. We will build a logistic regression model and estimate its test error using the validation set approach and the cross-validation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed8e43-d25a-4a02-988f-49ce67770870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to load the data\n",
    "Default = load_data('Default')\n",
    "Default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c6317-cf99-49d9-ae60-753f09eb793a",
   "metadata": {},
   "source": [
    "Background information on the dataset can be found [in the documentation](https://islp.readthedocs.io/en/latest/datasets/Default.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a75412-c7de-491e-b9be-d0ec886617b0",
   "metadata": {},
   "source": [
    "## Task 2.1\n",
    "Fit a logistic regression model that uses `income` and `balance` to predict `default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727109ed-48b7-4c9e-bc44-8c36b14a3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc651b-8665-48f2-a7d1-bfadb49d1c94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 2.2\n",
    "Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "\n",
    "i. Split the sample set into a training set and a validation set.\n",
    "\n",
    "ii. Fit a multiple logistic regression model using only the training observations.\n",
    "\n",
    "iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.\n",
    "\n",
    "iv. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a4cf7-6068-4c36-a14b-449001af21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e016c-9404-478e-9ca7-dd5b4d405bdf",
   "metadata": {},
   "source": [
    "## Task 2.3\n",
    "Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6678f73-12fb-4cc6-a898-c065e3d0247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856893a5-2422-4e97-8641-5bbe75504e0b",
   "metadata": {},
   "source": [
    "## Task 2.4\n",
    "Now predict the test error of the model using 10-fold cross-validation. To do so, follow the steps we developed in Part 1b) of this notebook.\n",
    "\n",
    "**Note**: To carry out this task, we need to define our own custom score using [`sklearn.make_scorer()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) and pass this to the function [`sklearn.cross_validate()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) by specifying it as an argument to the `scoring` parameter.\n",
    "\n",
    "Our custom scoring function needs to have the signature `score_func(y, y_pred, **kwargs)` with `y` being the true labels and `y_pred` the predicted labels as output by `sm.Logit()` when applying the `predict()` method. Since `statsmodels` outputs probabilities rather than actual labels, we first transform these probabilities  into labels. This is what our scoring function `accuracy_score_sm()` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5eb851-765d-499d-9cdb-4f9f2f2d26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define custom scorer which computes accuracy based on probabilities as\n",
    "# output by statsmodels\n",
    "from sklearn.metrics import make_scorer\n",
    "def accuracy_score_sm(y_true, y_pred_prob):\n",
    "    # computes the accuracy for the output of a binary classification model\n",
    "\n",
    "    # inputs:\n",
    "    #    y_true: ground truth labels, encoded as 0,1\n",
    "    #    y_pred_prob: probabilities for label 1 as predicted by the model\n",
    "\n",
    "    # output:\n",
    "    #    percentage of models \n",
    "    y_pred = ...\n",
    "    return ...\n",
    "accuracy_sm = make_scorer(...)\n",
    "\n",
    "# Step 2: Initialize splitter for cross validation and model\n",
    "cross_val = ...\n",
    "M = sklearn_sm(sm.Logit)\n",
    "\n",
    "# Step 3: Define response variable and design matrix for cross validation\n",
    "y = ...\n",
    "predictors = ...\n",
    "X = ...\n",
    "\n",
    "# Step 4: Run cross validation\n",
    "cv_results = cross_validate(M,\n",
    "                            X,\n",
    "                            y,\n",
    "                            scoring = accuracy_sm,\n",
    "                            cv = cross_val)\n",
    "print('Mean accuracy: ', np.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4eeec-0d91-4fb1-8ac1-8e066fedd68d",
   "metadata": {},
   "source": [
    "## Task 2.5\n",
    "Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using 10-fold cross-validation. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d922248-f09f-49b6-9b39-a873c4883974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
